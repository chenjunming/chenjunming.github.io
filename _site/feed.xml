<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-09-24T21:03:22+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">朝花夕拾</title><subtitle>陈俊铭的个人博客</subtitle><author><name>CHEN junming</name></author><entry><title type="html">Paxos</title><link href="http://localhost:4000/2019/09/24/Paxos/" rel="alternate" type="text/html" title="Paxos" /><published>2019-09-24T00:00:00+08:00</published><updated>2019-09-24T00:00:00+08:00</updated><id>http://localhost:4000/2019/09/24/Paxos</id><content type="html" xml:base="http://localhost:4000/2019/09/24/Paxos/">&lt;h1 id=&quot;2pc两阶段提交&quot;&gt;2PC(两阶段提交)&lt;/h1&gt;

&lt;p&gt;2PC协议有两个阶段：Propose和Commit&lt;/p&gt;

&lt;h2 id=&quot;无faliure情况下&quot;&gt;无faliure情况下&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190909183040036.png&quot; alt=&quot;image-20190909183040036&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;如果有一个voter在propose投了反对票则通过失败coordinator会在告诉所有voter放弃这个propose&quot;&gt;如果有一个voter在propose投了反对票，则通过失败，coordinator会在告诉所有voter放弃这个propose&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190909200954861.png&quot; alt=&quot;image-20190909200954861&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;缺陷&quot;&gt;缺陷&lt;/h2&gt;

&lt;p&gt;在commit阶段，如果coordinator和voter3都失联了，那么其他voter无法判断现在处于两种场景中的哪一种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;上轮全票通过然后voter3第一个收到commit的消息然后commit后crash了&lt;/li&gt;
  &lt;li&gt;voter3反对所以干脆没通过。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190909205531501.png&quot; alt=&quot;image-20190909205531501&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2PC 无法处理这种情况的原因是voter收到propose后，直接就commit，而没有在commit前通知其他节点已经收到propose的结果（commit or not），从而导致在coordinator和voter都掉线的情况下，无法知道当前是应该commit还是abort。为了解决这个问题，3PC了解一下。&lt;/p&gt;

&lt;h1 id=&quot;3pc三阶段提交&quot;&gt;3PC（三阶段提交）&lt;/h1&gt;

&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;

&lt;p&gt;​	简单来说，3PC就是把2PC的commit阶段拆分为了PreCommit和Commit阶段。通过新增的PreCommit阶段，voter可以知道上一阶段Propose的结果，但不会commit，而进入commit阶段，voter就可以知道其他voter都要commit，所以就能安心commit了。&lt;/p&gt;

&lt;p&gt;​	相当于加了一个barrier，在这个barrier之前（PreCommit之前），如果coordinator挂掉，则大家都知道不需要commit，会放弃掉当前的propose然后重新选一个coordinator出来；如果在barrier之后（PreCommit之后）coordinator挂掉，voter知道这是需要commit的，所以也就能安心commit。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190909211636589.png&quot; alt=&quot;image-20190909211636589&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;缺点&quot;&gt;缺点&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;不能处理网络分区的情况。
    &lt;ol&gt;
      &lt;li&gt;假设在PreCommit阶段所有节点被&lt;strong&gt;一分为二&lt;/strong&gt; （图示为3个voter，实际上需要两边的voter相等时才会出现这种情况），收到preCommit 消息的voter在一边，而没有收到这个消息的在另一边，在这种情况下，两边就可能会选出新的coordinator而做出不同的决定&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;/assets/image-20190924142101074.png&quot; alt=&quot;image-20190924142101074&quot; /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;3PC也不能处理fail-recover 的错误情况。简单来说，当coordinator收到preCommit的确认前crash了，于是voter重新选举一个新的coordinator 出来，当源coordinator重启之后，会向所有voter发送abort，因为它没有收到全部的preCommit 回复，此时可能会出现原coordinator 和 继任 coordinator 发送相矛盾的指令，从而出现节点的状态分歧。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;paxos&quot;&gt;Paxos&lt;/h1&gt;

&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;

&lt;p&gt;从整体上来说，Paxos 算法的目标就是要保证最终有一个提案会被选定，当提案被选定后，进程最终也能获取到被选定的提案。&lt;/p&gt;

&lt;h2 id=&quot;prepare-阶段&quot;&gt;Prepare 阶段&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;leader节点给所有其他acceptor节点发送消息“proposal(n)”——n 是该节点为这个提议选择的一个数字，姑且理解为一个方案编号，并期待该提议获得所有节点中的简单多数（Paxos的Quorum）许可&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每一个接收到proposal的acceptor节点：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;如果这是它接收到的第一个proposal&lt;/strong&gt;，回答“promise”.代表该节点许诺将会保持承认该proposal发送方为leader，&lt;strong&gt;除非收到其他优先级更高的proposal&lt;/strong&gt;；&lt;/p&gt;

        &lt;p&gt;如果已经有接收并accepted（注意：&lt;strong&gt;这是下一阶段可能会发生的动作&lt;/strong&gt;）其他的proposal(n’,v’)——n’是该proposal的方案号而v’是提议的公式&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;如果n &amp;lt; n’ ，之前accept的提议有更高优先级，对新接受的提议回答“reject”，以兑现之前的许诺&lt;/li&gt;
          &lt;li&gt;如果n &amp;gt; n’，回答“promise”并同时附上旧的提议，proposal(n’,v’)。这样在认可新的leader身份的同时，&lt;strong&gt;也告诉了新的leader过去的被简单多数认可过的提议&lt;/strong&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;prepare结果（reject）：如果proposer的提议受到了简单多数的“reject”，竞争leader宣告失败，可以放弃这一提议。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;prepare结果（promise）：如果接收到了简单多数的“promise”，则该proposer成为leader，它需要从收到的promise里附带的之前accepted的提议中选取方案号（n值）最高的对应的共识；如果历史上没有被accept过的提议，leader可以自己选取一个共识v。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;accept-阶段&quot;&gt;Accept 阶段&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;leader会多所有acceptor发送“accept-request(n,v)”，请求acceptor接受编号为n的共识v的提议。&lt;/li&gt;
  &lt;li&gt;每一个接收到该提议的acceptor节点：如果没有接受过&lt;strong&gt;编号比n更高的提议&lt;/strong&gt;，则返回“accept”标识接受这一共识提议，否则返回“reject”&lt;/li&gt;
  &lt;li&gt;如果简单多数的acceptor返回了“accept”，则共识达成；否则共识失败，重启paxos协议。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;注意&quot;&gt;注意&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;第一阶段竞争的并不是共识本身，而是在争取坐实leader身份获得简单多数的认可（编号越高代表优先级越高，但是并不代表优先级高的一定能抢到leader）&lt;/li&gt;
  &lt;li&gt;方案编号n本身并不是共识，而是提议的一个优先级，在多个节点竞争leader身份时可以区分优先顺序。共识本身（v）会在下一阶段leader身份确认后由leader添加进提议。&lt;/li&gt;
  &lt;li&gt;虽然这一轮只会有一个leader获得简单多数的认可，但可能有多个“糊涂”节点认为自己应该做leader。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;paxos对2pc和3pc有几点重要的改进&quot;&gt;Paxos对2PC和3PC有几点重要的改进&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;分离共识的提议者proposer以及帮助提议最终通过的leader这两个角色
    &lt;ol&gt;
      &lt;li&gt;即使一个leader身份被批准，它也需要尊重历史上其他被统一过的提议&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;对简单多数的巧妙应用
    &lt;ol&gt;
      &lt;li&gt;第一阶段里选举leader要求的简单多数保证了选举出来的leader一定不会错过之前被accept过的提议——所以就算那个提议最初的proposer挂了，也会至少被一个acceptor发给新的leader来继承。&lt;/li&gt;
      &lt;li&gt;第二阶段里要求的达成共识的简单多数保证了有多个“自以为是”的leader出现时（比如一个leader掉线，新leader选出，旧leader重新上线），一定只会有一个最后通过。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;paxos与2pc3pc-的关系&quot;&gt;Paxos与2PC/3PC 的关系&lt;/h2&gt;

&lt;h3 id=&quot;paxos如何克服2pc的问题&quot;&gt;Paxos如何克服2PC的问题：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;2PC中coordinator是唯一而固定的，如果coordinator宕机，那么就会有情形导致coordinator之前propose的提议的投票结果丢失。就算启动新的后背coordinator，没有机制可以学习以前的投票结果。&lt;/li&gt;
  &lt;li&gt;Paxos因为分离了协议和leader，从算法上保证总可以选举出后备leader并接替前任leader的工作。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;paxos-如何克服3pc的问题&quot;&gt;Paxos 如何克服3PC的问题：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;3PC发生的问题在于当有多个“自认的leader”出现时，并不能有效解决coordinator之间的竞争——谁是真正的coordinator&lt;/li&gt;
  &lt;li&gt;而Paxos通过Quorum的运用，保证了多个leader之间可以互相发现。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;paxos的局限性&quot;&gt;Paxos的局限性&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;活锁问题&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Paxos理论上存在一个不能终结协议的活锁竞争问题。比如一个proposer提交的提议因为编号过低被拒绝时，此proposer可能重启Paxos而提高编号重新提交。如果同时有两个proposer都发现自己的方案编号过低，从而轮流提出更高编号的proposal而导致对方被拒，可能会导致死循环（或活锁）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190924183619683.png&quot; alt=&quot;image-20190924183619683&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190924183635199.png&quot; alt=&quot;image-20190924183635199&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了保证Paxos算法流程的可持续性，以避免陷入“死循环“，就必须选择一个主proposer，并规定只有主proposer才能提出提案。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;恶意节点&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;目前为止2PC、3PC、Paxos均是假设所有节点都遵守协议的规定。当存在恶意的，可能发送任何导致协议停止或出错的消息的节点存在时，就需要有更强的共识算法在”守法节点“间达成共识。（拜占庭将军问题）&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">2PC(两阶段提交)</summary></entry><entry><title type="html">LSM树</title><link href="http://localhost:4000/2019/09/09/LSM/" rel="alternate" type="text/html" title="LSM树" /><published>2019-09-09T00:00:00+08:00</published><updated>2019-09-09T00:00:00+08:00</updated><id>http://localhost:4000/2019/09/09/LSM</id><content type="html" xml:base="http://localhost:4000/2019/09/09/LSM/">&lt;h1 id=&quot;lsm树&quot;&gt;LSM树&lt;/h1&gt;

&lt;h2 id=&quot;诞生原因&quot;&gt;诞生原因&lt;/h2&gt;

&lt;p&gt;传统关系型数据库使用btree或一些变体作为存储结构，能高效进行查找。但保存在磁盘中时它也有一个明显的缺陷，那就是&lt;strong&gt;逻辑上相离很近但物理却可能相隔很远&lt;/strong&gt;，这就可能造成大量的磁盘随机读写。&lt;strong&gt;随机读写比顺序读写慢很多&lt;/strong&gt;，为了提升IO性能，我们需要一种能将随机操作变为顺序操作的机制，于是便有了LSM树。&lt;strong&gt;LSM树能让我们进行顺序写磁盘，从而大幅提升写操作，作为代价的是牺牲了一些读性能&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;lsm树原理&quot;&gt;LSM树原理&lt;/h2&gt;

&lt;p&gt;LSM树由两个或以上的存储结构组成。为了说明简单，我们用两个存储结构来说明。一个存储结构常驻内存，称为C0 tree可以是任意方便键值对查找的数据结构，例如map，红黑树等；另一个存储结构常驻硬盘，类似B+树，C1的所有节点都是满的，节点大小等于磁盘块大小。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvwabvmt67j20mb08074p.jpg&quot;&gt;&lt;img src=&quot;/assets/910E16A4-A7DB-0F42-B917-373E31CF1E4E.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;插入步骤&quot;&gt;插入步骤&lt;/h2&gt;

&lt;p&gt;大体思路：插入一条记录时，先插入一条日志到末尾（append）。然后数据先插入到C0，因为是存储在内存中，所以是不涉及IO的；然后当C0 大小达到一个阈值，将C0记录滚动合并到C1中；对于多个存储结构，则逐层向上合并。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyan6q5iuj20lm06p0v1.jpg&quot;&gt;&lt;img src=&quot;/assets/FB74459A-1F5F-D043-A93A-F2C134EF06AB.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;示例&quot;&gt;示例&lt;/h2&gt;

&lt;p&gt;这里C0树使用AVL树，插入A，日志文件追加记录，再插入C0&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvym675zwpj20sf0fytza.jpg&quot;&gt;&lt;img src=&quot;/assets/A18998ED-D4E9-E145-BB14-9E8FC7A731D2.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;插入E&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvytpc19bqj20se0gkhdf.jpg&quot;&gt;&lt;img src=&quot;/assets/1F18E33F-DB26-D440-9CC3-4774E186EA72.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;插入L&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyts9vuqgj20sb0gfu0f.jpg&quot;&gt;&lt;img src=&quot;/assets/8685EC9C-F344-A545-A98F-27397BC1504F.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;插入“R”“U”，旋转后最终如下。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyv2am7l6j20s30g9nom.jpg&quot;&gt;&lt;img src=&quot;/assets/A6EB5771-D8E1-C147-B71C-65F333256F13.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;假如此时触发合并，因为C1还没有树，所以emptying block为空，直接从C0树从小到大依次找节点，放到filling blcok。&lt;/p&gt;

&lt;p&gt;放入最小节点A。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyv4durm3j20s50g7hcr.jpg&quot;&gt;&lt;img src=&quot;/assets/4688AC4A-77A6-8C42-B0B7-F837E833BFFD.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;第二小节点E&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyv5tiaysj20ry0fv4or.jpg&quot;&gt;&lt;img src=&quot;/assets/BCEA6E9F-F1E5-414F-A7B2-9CC31F882CB7.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如此类推直到填满filling blcok&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyv94hhgxj20ro0fvtyi.jpg&quot;&gt;&lt;img src=&quot;/assets/1586EDAE-5072-3943-9FE9-BE46E08FF952.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;写入C1（B+树）&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyvcl95rsj20rm0fw4od.jpg&quot;&gt;&lt;img src=&quot;/assets/E4ADE200-B8C5-2343-9A70-094883D09784.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;继续插入B F N T，先分别写日志，然后插入到内存的C0树中，&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyvfu7o7vj20s30g0tzt.jpg&quot;&gt;&lt;img src=&quot;/assets/7FD813DF-0ECC-C740-9B7B-E50A7A605FE0.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;假如此时触发合并，先加载C1的最左节点（最小）到emptying blcok&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyvvf2qe4j20s40gcnok.jpg&quot;&gt;&lt;img src=&quot;/assets/54BCAFA3-4E62-7E40-84CB-811BEEE755C5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后将C0树的节点和emptying blcok 合并排序，首先是A进入filling blcok&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyw1b3aioj20s70g6qu0.jpg&quot;&gt;&lt;img src=&quot;/assets/DA22C7CD-4005-CD42-8402-4BB03FD88621.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后是B&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyw4txnntj20rz0fuqte.jpg&quot;&gt;&lt;img src=&quot;/assets/3B845EA3-C248-2E48-829D-455B4A4687F4.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如此类推&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyw7cxxq1j20rh0g77ua.jpg&quot;&gt;&lt;img src=&quot;/assets/017566F2-383D-1847-A60C-26D6C8DDD0C5.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;将filling blcok追加到磁盘的新位置，将原来的节点删掉&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvywe17gonj20rj0fqkh6.jpg&quot;&gt;&lt;img src=&quot;/assets/1E99999C-0D7B-FD46-93E2-27B3DAAE2FB0.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;继续合并，再次填满filling blcok&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvywk53gmej20rw0gd1jo.jpg&quot;&gt;&lt;img src=&quot;/assets/B99A1113-1DAA-254C-935D-3732983C3F49.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;将filling blcok 追加到磁盘的新位置，&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvywtrigujj20uj0fw1kx.jpg&quot;&gt;&lt;img src=&quot;/assets/0A43D0DA-54FB-D345-9674-F7F00FF98BED.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;查找&quot;&gt;查找&lt;/h2&gt;

&lt;p&gt;总体思想是从最顶层开始查找，如果C0不存在，继续去C1找如此类推。&lt;/p&gt;

&lt;p&gt;例如要找“B”，从C0开始找没找到&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyxegpe23j20u70g71kx.jpg&quot;&gt;&lt;img src=&quot;/assets/063410EB-8798-C448-B417-4267C6906A1D.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后找C1树 树根开始找&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyxgsbj4tj20v40g84qp.jpg&quot;&gt;&lt;img src=&quot;/assets/6F9F9839-0F52-174C-93C4-6E582A09DA80.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;找到“B”。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyxikpcjjj20v70fn1kx.jpg&quot;&gt;&lt;img src=&quot;/assets/56823EF4-20B7-8449-8BDB-1951C28290DD.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;删除操作&quot;&gt;删除操作&lt;/h2&gt;

&lt;p&gt;删除为了能快速执行，标记一下，等下次合并的时候删除相应的记录。&lt;/p&gt;

&lt;p&gt;加入要删除“U”，假设标为“#”的表示删除&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyxstu99nj20ui0gj4qp.jpg&quot;&gt;&lt;img src=&quot;/assets/4EA4D5A1-50B5-EF44-A3DD-95F1F1754071.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;而如果要删除的key不在C0，则只需要在C0中标志该key已删除，而不需要去硬盘查找。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gitee.com/chenssy/blog-home/raw/master/image/series-images/sjjg/sjjg-kt/b905aa66ly1fvyxwx9l7nj20uh0fw1kx.jpg&quot;&gt;&lt;img src=&quot;/assets/511043A0-B736-884B-B154-9EC23A8AB386.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">LSM树</summary></entry><entry><title type="html">视频直播CDN技术</title><link href="http://localhost:4000/2019/07/16/vedio_cnd/" rel="alternate" type="text/html" title="视频直播CDN技术" /><published>2019-07-16T00:00:00+08:00</published><updated>2019-07-16T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/16/vedio_cnd</id><content type="html" xml:base="http://localhost:4000/2019/07/16/vedio_cnd/">&lt;h1 id=&quot;视频直播cdn技术&quot;&gt;视频直播CDN技术&lt;/h1&gt;

&lt;h2 id=&quot;定义&quot;&gt;定义&lt;/h2&gt;

&lt;h3 id=&quot;视频&quot;&gt;视频&lt;/h3&gt;

&lt;p&gt;通常我们所说的视频，是指&lt;strong&gt;连续的图像变化每秒超过24帧（Frame）画面以上&lt;/strong&gt;时，根据视觉暂留原理，人眼无法辨别单幅的静态画面，看上去是平滑连续的视觉效果，这样连续的画面叫做视频。&lt;/p&gt;

&lt;h3 id=&quot;转码&quot;&gt;转码&lt;/h3&gt;

&lt;p&gt;媒体转码是指将一段多媒体包括音频、视频或者其他的内容从一种编码格式转换成为另外一种编码格式。&lt;/p&gt;

&lt;h3 id=&quot;码率&quot;&gt;码率&lt;/h3&gt;

&lt;p&gt;码率是数据传输时单位时间传送的数据位数，一般我们用的单位是kbps即千位每秒。通俗一点的理解就是取样率，单位时间内取样率越大，精度就越高，处理出来的文件就越接近原始文件，但是文件体积与取样率是成正比的，所以几乎所有的编码格式重视的都是如何用最低的码率达到最少的失真。但是因为编码算法不一样，所以也不能用码率来统一衡量音质或画质。&lt;/p&gt;

&lt;h3 id=&quot;帧&quot;&gt;帧&lt;/h3&gt;

&lt;p&gt;它是一段数据的组合，是数据传输的基本单位。就是影像动画中最小单位的单幅影像画面，相当于电影胶片上的每一格镜头。一帧就是一副静止的画面，连续的帧就形成动画，如电视图像等。&lt;/p&gt;

&lt;h3 id=&quot;帧率&quot;&gt;帧率&lt;/h3&gt;

&lt;p&gt;每秒显示的帧数，帧率表示图形处理器处理时每秒能够更新的次数。高的帧率可以得到更流畅、更逼真的动画。一般来说30fps就是可以接受的。但是将性能提升至60fps则可以明显提升交互干和逼真感，但是一般来说超过75fps一般就不容易察觉到有明显的流畅度提升了。如果帧率超过屏幕刷新率只会浪费图形处理的能力，因为显示器不能以这么快的速度更新，这样超过刷新率的帧率就浪费掉了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190714204141209.png&quot; alt=&quot;image-20190714204141209&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;音频帧一般可以独立解码，可以直接播放。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;而视频分为视频关键帧和非关键帧，&lt;strong&gt;关键帧可以独立解码渲染&lt;/strong&gt;，播放器拿到后可以直接看到画面，一般10k以上甚至几十k；其他非关键帧解码依赖于前面的一些视频帧，&lt;strong&gt;播放器会根据前面的帧和这一帧（非关键帧）来解码产生画面&lt;/strong&gt;，非关键帧一般大小是几k甚至不到1k。&lt;strong&gt;对于播放器来说，服务器一般会从视频关键帧开始发送，这样才不会产生花屏&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于节点上直播服务器存储的内容，如果是文件加速，节点上存储的内容很明确，就是文件数据，URL不变的话文件数据内容也不变。但是对于直播来讲，传输的就是帧数据，缓存的也是不断变化的帧序列数据。&lt;/p&gt;

&lt;p&gt;下面的图里我们可以看到，当前的服务器缓存了 V1-V3 五帧数据，当 V4 这个关键帧出现了，服务器把之前的丢掉，开始缓存 V4 开始的音视频数据，以这个策略保证过来的播放端都是当前最新的数据。一般直播服务器都是用这个策略来进行服务器缓存的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/d3fc57ebe4fe4a52ac05f8b28d61c60d.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;直播和点播的异同&quot;&gt;直播和点播的异同&lt;/h2&gt;

&lt;h3 id=&quot;相同点&quot;&gt;相同点&lt;/h3&gt;

&lt;p&gt;对于播放端来说，直播和点播都是向服务器获取视频数据，播放端对声音和画面进行播放的过程。从这个角度来讲，直播和点播区别不大。&lt;/p&gt;

&lt;h3 id=&quot;差异&quot;&gt;差异&lt;/h3&gt;

&lt;p&gt;点播可以选择快进和回退，直播却不能。&lt;/p&gt;

&lt;p&gt;直播就是每一帧数据打上时序标签后进行流式传输的过程，发送端源源不断的采集音视频数据，经过编码、封包、推流、再经过分发网络进行扩散传播，播放端再源源不断地下载数据并按时序进行解码播放。如此就产生了边生产、边传输、边消费的直播过程。&lt;/p&gt;

&lt;p&gt;我们将视频直播整个流程主要分为几个关键阶段：视频采集、前处理、编码、推流、转码、分发、播放，如下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190715182615646.png&quot; alt=&quot;image-20190715182615646&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1-采集&quot;&gt;1. 采集&lt;/h4&gt;

&lt;p&gt;是视频直播开始的第一个环节，用户可以通过不同的终端采集视频，也就是主播直播的过程。&lt;/p&gt;

&lt;h4 id=&quot;2-前处理&quot;&gt;2. 前处理&lt;/h4&gt;

&lt;p&gt;美颜，水印、模糊特效等。（针对不同的终端要提供不同的处理库）&lt;/p&gt;

&lt;h4 id=&quot;3-编码&quot;&gt;3. 编码&lt;/h4&gt;

&lt;p&gt;编码时候我们需要处理硬件兼容性问题和寻求码率和画质之前的平衡。&lt;/p&gt;

&lt;h4 id=&quot;4-推流与转码&quot;&gt;4. 推流与转码&lt;/h4&gt;

&lt;p&gt;在数据传输的整个过程中从主播端到服务端，再到边缘节点，以及从边缘节点到播放端。为了让采集端的流适配各个平台端不同协议，一般都会在服务端进行转码处理，将视频文件转成不同格式，支持 RTMP、HLS 和 FLV 等不同的协议。&lt;/p&gt;

&lt;h4 id=&quot;5-分发&quot;&gt;5. 分发&lt;/h4&gt;

&lt;p&gt;随着移动直播兴起和游戏直播的持续火热，网络直播平台支持亿级高并发是理论上应该做到的，为了优化终端观看直播的体验，一般都会采用 CDN 进行内容分发加速，实现高并发等能力。&lt;/p&gt;

&lt;h4 id=&quot;6-客户端播放&quot;&gt;6. 客户端播放&lt;/h4&gt;

&lt;p&gt;也就是解码和渲染。通常秒开、低延迟等问题是需要在播放端来克服的。&lt;/p&gt;

&lt;h2 id=&quot;直播架构&quot;&gt;直播架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/c49f73abfa0e4da69bd33bf3d2725e8c.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对于推流端推流，目前主要使用的是 RTMP 协议，播放可以使用 RTMP、HTTP FLV 和 HLS 协议，常用的推流端是 OBS、手机 APP、FFmpeg；播放端包括 Flash、VLC、HTML5、手机 APP 等形式；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;视频直播中心拥有稳定的推流上行链路，支持连麦、IM、直播间管理等分丰富的直播服务端实现流能力；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CDN 直播分发提供流畅的播放下行链路，700 多个国内节点和 300 多个海外节点，还有丰富的小运营商节点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于播放端，我们做了首屏秒开优化和弱网跳帧播放，确保用户体验。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;视频直播是非常典型的发布和订阅关系。&lt;/p&gt;

&lt;p&gt;从下图可以看到，主播完成发布动作，这条直播内容也就是这一路流推动到服务器，三个观众也就是订阅者，从服务器拉流，也就是用播放动作来完成推流。这种进程内部、节点之间的发布、订阅关系是一种级联的关系，CDN 的直播分发就是依靠这种模式构建。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/338430fb45324b758cf1b7d439744d96.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;internet-backboneinternet-骨干网&quot;&gt;Internet backbone：Internet 骨干网&lt;/h3&gt;

&lt;p&gt;几台计算机连接起来，互相可以看到其他人的文件，这叫局域网，整个城市的计算机都连接起来，就是城域网。&lt;strong&gt;把城市之间连接起来的网就叫骨干网&lt;/strong&gt;。&lt;strong&gt;这些骨干网是国家批准的可以直接和国外连接的互联网&lt;/strong&gt;。其他有接入功能的ISP（互联网服务提供商）想连到国外都得通过这些骨干网。&lt;/p&gt;

&lt;h3 id=&quot;基础架构&quot;&gt;基础架构&lt;/h3&gt;

&lt;p&gt;内容通过存储集群到达发布集群，再通过骨干中转环境的 L2，利用 CDN 智能调度到达 L1，也就是距离用户最近的节点，从顺利的推送给用户。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/c77d9e2e7aeb4914b747b2c937e2a528.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">视频直播CDN技术</summary></entry><entry><title type="html">Spark读取数据的方式</title><link href="http://localhost:4000/2019/07/11/spark-read-data-style/" rel="alternate" type="text/html" title="Spark读取数据的方式" /><published>2019-07-11T00:00:00+08:00</published><updated>2019-07-11T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/11/spark-read-data-style</id><content type="html" xml:base="http://localhost:4000/2019/07/11/spark-read-data-style/">&lt;h1 id=&quot;spark读取数据的方式&quot;&gt;Spark读取数据的方式&lt;/h1&gt;

&lt;h2 id=&quot;hdfs&quot;&gt;HDFS&lt;/h2&gt;

&lt;h3 id=&quot;hdfs架构&quot;&gt;hdfs架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190625171543858.png&quot; alt=&quot;image-20190625171543858&quot; /&gt;&lt;/p&gt;

&lt;p&gt;hdfs把文件按照&lt;strong&gt;字节&lt;/strong&gt;切分成多个block，每个block的大小相等。&lt;/p&gt;

&lt;p&gt;Namenode：存储元数据&lt;/p&gt;

&lt;p&gt;Datanode：包含多个block&lt;/p&gt;

&lt;h3 id=&quot;读取原理&quot;&gt;读取原理&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190625181329664.png&quot; alt=&quot;image-20190625181329664&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“断行问题”&lt;/strong&gt;：既然无法断定每一个split开始的一行是独立的一行还是被切断的一行的一部分,那就跳过每个split的开始一行(当然要除第一个split之外),从第二行开始读取,然后在到达split的结尾端时总是再多读一行,这样数据既能接续起来又避开了断行带来的麻烦.&lt;/p&gt;

&lt;h2 id=&quot;mysql&quot;&gt;Mysql&lt;/h2&gt;

&lt;p&gt;使用的是mysql 5.7.26&lt;/p&gt;

&lt;h3 id=&quot;使用limit-的缺陷&quot;&gt;使用limit 的缺陷：&lt;/h3&gt;

&lt;p&gt;offset过大影响性能:&lt;/p&gt;

&lt;p&gt;https://blog.csdn.net/fdipzone/article/details/72793837&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- 第一时间想到的扫表方式，效率很低&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 利用索引进行扫描&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626113609306.png&quot; alt=&quot;image-20190626113609306&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;分析影响性能原因&quot;&gt;分析影响性能原因&lt;/h3&gt;

&lt;p&gt;因为数据表是InnoDB，根据InnoDB索引的结构，查询过程为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从数据表中读取第N条数据添加到数据集中&lt;/li&gt;
  &lt;li&gt;重复第一步直到N= 800000 + 10&lt;/li&gt;
  &lt;li&gt;根据offset抛弃前面800000 条数&lt;/li&gt;
  &lt;li&gt;返回剩余的10 条数据&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;显然，导致这句sql速度慢的问题出现在第二步。前面的80w条数据完全对本次的查询没有意义，却占据了绝大部分的查询时间。如何解决？&lt;/p&gt;

&lt;p&gt;核心思想:&lt;strong&gt;先找到数据块，再根据offset的值做偏移处理。 ——&amp;gt; 先执行偏移处理，跳过前面80w条数据，再读取数据块。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/SouthEast.jpeg&quot; alt=&quot;è¿éåå¾çæè¿°&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用between（B+树特性）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626115737271.png&quot; alt=&quot;image-20190626115737271&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只使用order by&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626141626550.png&quot; alt=&quot;image-20190626141626550&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka&lt;/h2&gt;

&lt;p&gt;direct方式（类似于HDFS）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626181024651.png&quot; alt=&quot;image-20190626181024651&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626181240352.png&quot; alt=&quot;image-20190626181240352&quot; /&gt;&lt;/p&gt;

&lt;p&gt;消费偏移量由spark streaming自己来管理，数据处理成功就更新偏移量，处理失败，就去kafka中重新读取数据，exactly once 的事务支持的比较好。&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">Spark读取数据的方式</summary></entry></feed>