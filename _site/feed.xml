<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-07-11T20:19:11+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">朝花夕拾</title><subtitle>陈俊铭的个人博客</subtitle><author><name>CHEN junming</name></author><entry><title type="html">Spark读取数据的方式</title><link href="http://localhost:4000/2019/07/11/spark-read-data-style/" rel="alternate" type="text/html" title="Spark读取数据的方式" /><published>2019-07-11T00:00:00+08:00</published><updated>2019-07-11T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/11/spark-read-data-style</id><content type="html" xml:base="http://localhost:4000/2019/07/11/spark-read-data-style/">&lt;h1 id=&quot;spark读取数据的方式&quot;&gt;Spark读取数据的方式&lt;/h1&gt;

&lt;h2 id=&quot;hdfs&quot;&gt;HDFS&lt;/h2&gt;

&lt;h3 id=&quot;hdfs架构&quot;&gt;hdfs架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190625171543858.png&quot; alt=&quot;image-20190625171543858&quot; /&gt;&lt;/p&gt;

&lt;p&gt;hdfs把文件按照&lt;strong&gt;字节&lt;/strong&gt;切分成多个block，每个block的大小相等。&lt;/p&gt;

&lt;p&gt;Namenode：存储元数据&lt;/p&gt;

&lt;p&gt;Datanode：包含多个block&lt;/p&gt;

&lt;h3 id=&quot;读取原理&quot;&gt;读取原理&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190625181329664.png&quot; alt=&quot;image-20190625181329664&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“断行问题”&lt;/strong&gt;：既然无法断定每一个split开始的一行是独立的一行还是被切断的一行的一部分,那就跳过每个split的开始一行(当然要除第一个split之外),从第二行开始读取,然后在到达split的结尾端时总是再多读一行,这样数据既能接续起来又避开了断行带来的麻烦.&lt;/p&gt;

&lt;h2 id=&quot;mysql&quot;&gt;Mysql&lt;/h2&gt;

&lt;p&gt;使用的是mysql 5.7.26&lt;/p&gt;

&lt;h3 id=&quot;使用limit-的缺陷&quot;&gt;使用limit 的缺陷：&lt;/h3&gt;

&lt;p&gt;offset过大影响性能:&lt;/p&gt;

&lt;p&gt;https://blog.csdn.net/fdipzone/article/details/72793837&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- 第一时间想到的扫表方式，效率很低&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 利用索引进行扫描&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626113609306.png&quot; alt=&quot;image-20190626113609306&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;分析影响性能原因&quot;&gt;分析影响性能原因&lt;/h3&gt;

&lt;p&gt;因为数据表是InnoDB，根据InnoDB索引的结构，查询过程为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从数据表中读取第N条数据添加到数据集中&lt;/li&gt;
  &lt;li&gt;重复第一步直到N= 800000 + 10&lt;/li&gt;
  &lt;li&gt;根据offset抛弃前面800000 条数&lt;/li&gt;
  &lt;li&gt;返回剩余的10 条数据&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;显然，导致这句sql速度慢的问题出现在第二步。前面的80w条数据完全对本次的查询没有意义，却占据了绝大部分的查询时间。如何解决？&lt;/p&gt;

&lt;p&gt;核心思想:&lt;strong&gt;先找到数据块，再根据offset的值做偏移处理。 ——&amp;gt; 先执行偏移处理，跳过前面80w条数据，再读取数据块。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/SouthEast.jpeg&quot; alt=&quot;è¿éåå¾çæè¿°&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用between（B+树特性）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626115737271.png&quot; alt=&quot;image-20190626115737271&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只使用order by&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626141626550.png&quot; alt=&quot;image-20190626141626550&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka&lt;/h2&gt;

&lt;p&gt;direct方式（类似于HDFS）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626181024651.png&quot; alt=&quot;image-20190626181024651&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626181240352.png&quot; alt=&quot;image-20190626181240352&quot; /&gt;&lt;/p&gt;

&lt;p&gt;消费偏移量由spark streaming自己来管理，数据处理成功就更新偏移量，处理失败，就去kafka中重新读取数据，exactly once 的事务支持的比较好。&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">Spark读取数据的方式</summary></entry></feed>