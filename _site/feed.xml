<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-07-16T10:27:17+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">朝花夕拾</title><subtitle>陈俊铭的个人博客</subtitle><author><name>CHEN junming</name></author><entry><title type="html">视频直播CDN技术</title><link href="http://localhost:4000/2019/07/16/vedio_cnd/" rel="alternate" type="text/html" title="视频直播CDN技术" /><published>2019-07-16T00:00:00+08:00</published><updated>2019-07-16T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/16/vedio_cnd</id><content type="html" xml:base="http://localhost:4000/2019/07/16/vedio_cnd/">&lt;h1 id=&quot;视频直播cdn技术&quot;&gt;视频直播CDN技术&lt;/h1&gt;

&lt;h2 id=&quot;定义&quot;&gt;定义&lt;/h2&gt;

&lt;h3 id=&quot;视频&quot;&gt;视频&lt;/h3&gt;

&lt;p&gt;通常我们所说的视频，是指&lt;strong&gt;连续的图像变化每秒超过24帧（Frame）画面以上&lt;/strong&gt;时，根据视觉暂留原理，人眼无法辨别单幅的静态画面，看上去是平滑连续的视觉效果，这样连续的画面叫做视频。&lt;/p&gt;

&lt;h3 id=&quot;转码&quot;&gt;转码&lt;/h3&gt;

&lt;p&gt;媒体转码是指将一段多媒体包括音频、视频或者其他的内容从一种编码格式转换成为另外一种编码格式。&lt;/p&gt;

&lt;h3 id=&quot;码率&quot;&gt;码率&lt;/h3&gt;

&lt;p&gt;码率是数据传输时单位时间传送的数据位数，一般我们用的单位是kbps即千位每秒。通俗一点的理解就是取样率，单位时间内取样率越大，精度就越高，处理出来的文件就越接近原始文件，但是文件体积与取样率是成正比的，所以几乎所有的编码格式重视的都是如何用最低的码率达到最少的失真。但是因为编码算法不一样，所以也不能用码率来统一衡量音质或画质。&lt;/p&gt;

&lt;h3 id=&quot;帧&quot;&gt;帧&lt;/h3&gt;

&lt;p&gt;它是一段数据的组合，是数据传输的基本单位。就是影像动画中最小单位的单幅影像画面，相当于电影胶片上的每一格镜头。一帧就是一副静止的画面，连续的帧就形成动画，如电视图像等。&lt;/p&gt;

&lt;h3 id=&quot;帧率&quot;&gt;帧率&lt;/h3&gt;

&lt;p&gt;每秒显示的帧数，帧率表示图形处理器处理时每秒能够更新的次数。高的帧率可以得到更流畅、更逼真的动画。一般来说30fps就是可以接受的。但是将性能提升至60fps则可以明显提升交互干和逼真感，但是一般来说超过75fps一般就不容易察觉到有明显的流畅度提升了。如果帧率超过屏幕刷新率只会浪费图形处理的能力，因为显示器不能以这么快的速度更新，这样超过刷新率的帧率就浪费掉了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190714204141209.png&quot; alt=&quot;image-20190714204141209&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;音频帧一般可以独立解码，可以直接播放。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;而视频分为视频关键帧和非关键帧，&lt;strong&gt;关键帧可以独立解码渲染&lt;/strong&gt;，播放器拿到后可以直接看到画面，一般10k以上甚至几十k；其他非关键帧解码依赖于前面的一些视频帧，&lt;strong&gt;播放器会根据前面的帧和这一帧（非关键帧）来解码产生画面&lt;/strong&gt;，非关键帧一般大小是几k甚至不到1k。&lt;strong&gt;对于播放器来说，服务器一般会从视频关键帧开始发送，这样才不会产生花屏&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对于节点上直播服务器存储的内容，如果是文件加速，节点上存储的内容很明确，就是文件数据，URL不变的话文件数据内容也不变。但是对于直播来讲，传输的就是帧数据，缓存的也是不断变化的帧序列数据。&lt;/p&gt;

&lt;p&gt;下面的图里我们可以看到，当前的服务器缓存了 V1-V3 五帧数据，当 V4 这个关键帧出现了，服务器把之前的丢掉，开始缓存 V4 开始的音视频数据，以这个策略保证过来的播放端都是当前最新的数据。一般直播服务器都是用这个策略来进行服务器缓存的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/d3fc57ebe4fe4a52ac05f8b28d61c60d.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;直播和点播的异同&quot;&gt;直播和点播的异同&lt;/h2&gt;

&lt;h3 id=&quot;相同点&quot;&gt;相同点&lt;/h3&gt;

&lt;p&gt;对于播放端来说，直播和点播都是向服务器获取视频数据，播放端对声音和画面进行播放的过程。从这个角度来讲，直播和点播区别不大。&lt;/p&gt;

&lt;h3 id=&quot;差异&quot;&gt;差异&lt;/h3&gt;

&lt;p&gt;点播可以选择快进和回退，直播却不能。&lt;/p&gt;

&lt;p&gt;直播就是每一帧数据打上时序标签后进行流式传输的过程，发送端源源不断的采集音视频数据，经过编码、封包、推流、再经过分发网络进行扩散传播，播放端再源源不断地下载数据并按时序进行解码播放。如此就产生了边生产、边传输、边消费的直播过程。&lt;/p&gt;

&lt;p&gt;我们将视频直播整个流程主要分为几个关键阶段：视频采集、前处理、编码、推流、转码、分发、播放，如下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190715182615646.png&quot; alt=&quot;image-20190715182615646&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1-采集&quot;&gt;1. 采集&lt;/h4&gt;

&lt;p&gt;是视频直播开始的第一个环节，用户可以通过不同的终端采集视频，也就是主播直播的过程。&lt;/p&gt;

&lt;h4 id=&quot;2-前处理&quot;&gt;2. 前处理&lt;/h4&gt;

&lt;p&gt;美颜，水印、模糊特效等。（针对不同的终端要提供不同的处理库）&lt;/p&gt;

&lt;h4 id=&quot;3-编码&quot;&gt;3. 编码&lt;/h4&gt;

&lt;p&gt;编码时候我们需要处理硬件兼容性问题和寻求码率和画质之前的平衡。&lt;/p&gt;

&lt;h4 id=&quot;4-推流与转码&quot;&gt;4. 推流与转码&lt;/h4&gt;

&lt;p&gt;在数据传输的整个过程中从主播端到服务端，再到边缘节点，以及从边缘节点到播放端。为了让采集端的流适配各个平台端不同协议，一般都会在服务端进行转码处理，将视频文件转成不同格式，支持 RTMP、HLS 和 FLV 等不同的协议。&lt;/p&gt;

&lt;h4 id=&quot;5-分发&quot;&gt;5. 分发&lt;/h4&gt;

&lt;p&gt;随着移动直播兴起和游戏直播的持续火热，网络直播平台支持亿级高并发是理论上应该做到的，为了优化终端观看直播的体验，一般都会采用 CDN 进行内容分发加速，实现高并发等能力。&lt;/p&gt;

&lt;h4 id=&quot;6-客户端播放&quot;&gt;6. 客户端播放&lt;/h4&gt;

&lt;p&gt;也就是解码和渲染。通常秒开、低延迟等问题是需要在播放端来克服的。&lt;/p&gt;

&lt;h2 id=&quot;直播架构&quot;&gt;直播架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/c49f73abfa0e4da69bd33bf3d2725e8c.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对于推流端推流，目前主要使用的是 RTMP 协议，播放可以使用 RTMP、HTTP FLV 和 HLS 协议，常用的推流端是 OBS、手机 APP、FFmpeg；播放端包括 Flash、VLC、HTML5、手机 APP 等形式；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;视频直播中心拥有稳定的推流上行链路，支持连麦、IM、直播间管理等分丰富的直播服务端实现流能力；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;CDN 直播分发提供流畅的播放下行链路，700 多个国内节点和 300 多个海外节点，还有丰富的小运营商节点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于播放端，我们做了首屏秒开优化和弱网跳帧播放，确保用户体验。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;视频直播是非常典型的发布和订阅关系。&lt;/p&gt;

&lt;p&gt;从下图可以看到，主播完成发布动作，这条直播内容也就是这一路流推动到服务器，三个观众也就是订阅者，从服务器拉流，也就是用播放动作来完成推流。这种进程内部、节点之间的发布、订阅关系是一种级联的关系，CDN 的直播分发就是依靠这种模式构建。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/338430fb45324b758cf1b7d439744d96.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;internet-backboneinternet-骨干网&quot;&gt;Internet backbone：Internet 骨干网&lt;/h3&gt;

&lt;p&gt;几台计算机连接起来，互相可以看到其他人的文件，这叫局域网，整个城市的计算机都连接起来，就是城域网。&lt;strong&gt;把城市之间连接起来的网就叫骨干网&lt;/strong&gt;。&lt;strong&gt;这些骨干网是国家批准的可以直接和国外连接的互联网&lt;/strong&gt;。其他有接入功能的ISP（互联网服务提供商）想连到国外都得通过这些骨干网。&lt;/p&gt;

&lt;h3 id=&quot;基础架构&quot;&gt;基础架构&lt;/h3&gt;

&lt;p&gt;内容通过存储集群到达发布集群，再通过骨干中转环境的 L2，利用 CDN 智能调度到达 L1，也就是距离用户最近的节点，从顺利的推送给用户。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/c77d9e2e7aeb4914b747b2c937e2a528.jpeg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">视频直播CDN技术</summary></entry><entry><title type="html">Spark读取数据的方式</title><link href="http://localhost:4000/2019/07/11/spark-read-data-style/" rel="alternate" type="text/html" title="Spark读取数据的方式" /><published>2019-07-11T00:00:00+08:00</published><updated>2019-07-11T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/11/spark-read-data-style</id><content type="html" xml:base="http://localhost:4000/2019/07/11/spark-read-data-style/">&lt;h1 id=&quot;spark读取数据的方式&quot;&gt;Spark读取数据的方式&lt;/h1&gt;

&lt;h2 id=&quot;hdfs&quot;&gt;HDFS&lt;/h2&gt;

&lt;h3 id=&quot;hdfs架构&quot;&gt;hdfs架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190625171543858.png&quot; alt=&quot;image-20190625171543858&quot; /&gt;&lt;/p&gt;

&lt;p&gt;hdfs把文件按照&lt;strong&gt;字节&lt;/strong&gt;切分成多个block，每个block的大小相等。&lt;/p&gt;

&lt;p&gt;Namenode：存储元数据&lt;/p&gt;

&lt;p&gt;Datanode：包含多个block&lt;/p&gt;

&lt;h3 id=&quot;读取原理&quot;&gt;读取原理&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190625181329664.png&quot; alt=&quot;image-20190625181329664&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“断行问题”&lt;/strong&gt;：既然无法断定每一个split开始的一行是独立的一行还是被切断的一行的一部分,那就跳过每个split的开始一行(当然要除第一个split之外),从第二行开始读取,然后在到达split的结尾端时总是再多读一行,这样数据既能接续起来又避开了断行带来的麻烦.&lt;/p&gt;

&lt;h2 id=&quot;mysql&quot;&gt;Mysql&lt;/h2&gt;

&lt;p&gt;使用的是mysql 5.7.26&lt;/p&gt;

&lt;h3 id=&quot;使用limit-的缺陷&quot;&gt;使用limit 的缺陷：&lt;/h3&gt;

&lt;p&gt;offset过大影响性能:&lt;/p&gt;

&lt;p&gt;https://blog.csdn.net/fdipzone/article/details/72793837&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;-- 第一时间想到的扫表方式，效率很低&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 利用索引进行扫描&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626113609306.png&quot; alt=&quot;image-20190626113609306&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;分析影响性能原因&quot;&gt;分析影响性能原因&lt;/h3&gt;

&lt;p&gt;因为数据表是InnoDB，根据InnoDB索引的结构，查询过程为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从数据表中读取第N条数据添加到数据集中&lt;/li&gt;
  &lt;li&gt;重复第一步直到N= 800000 + 10&lt;/li&gt;
  &lt;li&gt;根据offset抛弃前面800000 条数&lt;/li&gt;
  &lt;li&gt;返回剩余的10 条数据&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;显然，导致这句sql速度慢的问题出现在第二步。前面的80w条数据完全对本次的查询没有意义，却占据了绝大部分的查询时间。如何解决？&lt;/p&gt;

&lt;p&gt;核心思想:&lt;strong&gt;先找到数据块，再根据offset的值做偏移处理。 ——&amp;gt; 先执行偏移处理，跳过前面80w条数据，再读取数据块。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/SouthEast.jpeg&quot; alt=&quot;è¿éåå¾çæè¿°&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用between（B+树特性）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626115737271.png&quot; alt=&quot;image-20190626115737271&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只使用order by&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626141626550.png&quot; alt=&quot;image-20190626141626550&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka&lt;/h2&gt;

&lt;p&gt;direct方式（类似于HDFS）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626181024651.png&quot; alt=&quot;image-20190626181024651&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image-20190626181240352.png&quot; alt=&quot;image-20190626181240352&quot; /&gt;&lt;/p&gt;

&lt;p&gt;消费偏移量由spark streaming自己来管理，数据处理成功就更新偏移量，处理失败，就去kafka中重新读取数据，exactly once 的事务支持的比较好。&lt;/p&gt;</content><author><name>CHEN junming</name></author><summary type="html">Spark读取数据的方式</summary></entry></feed>